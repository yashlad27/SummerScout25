# ğŸ¯ InternTracker

**On-demand command-line tool to track Summer 2026 tech internships across 108 top companies.**

No cloud required. No 24/7 running. Just scrape when you want, get results, done.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

## âœ¨ Features

- ğŸš€ **On-Demand Scraping** - Run only when you need it
- ğŸ–¥ï¸ **Interactive CLI** - Full-featured terminal app for managing jobs
- ğŸ¯ **327 Companies** - FAANG, quant firms, unicorn startups, fintech
- ğŸ‡ºğŸ‡¸ **US Positions Only** - Automatically filtered
- ğŸ’¼ **Internship Focus** - Summer 2026 Masters-eligible positions
- ğŸ“Š **Smart Filtering** - ML/AI, Cybersecurity, Data Engineering, Data Science
- ğŸ”” **Email Notifications** - Get alerts for new postings
- ğŸ’¾ **Master CSV Log** - Comprehensive job database updated automatically
- ğŸ“ˆ **Statistics Dashboard** - Track daily/all-time metrics
- ğŸª¶ **Lightweight** - Docker stops when done

## ğŸ¬ Demo

### Interactive CLI (NEW!)
```bash
# Launch interactive terminal app
$ ./job_tracker.sh

================================================================================
ğŸ¯  JOB TRACKER - Interactive CLI
================================================================================

ğŸ“‹ MAIN MENU:
--------------------------------------------------------------------------------
  1. ğŸš€ Run Full Scrape (All 327 Companies)
  2. ğŸ¯ Run Single Company Scrape
  3. ğŸ“Š View Today's Statistics
  4. ğŸ†• View New Jobs (Last 24 Hours)
  5. ğŸ“ˆ View All-Time Statistics
  6. ğŸ“ View Recent Export Files
  7. ğŸ’¾ Export Master Job Log (CSV)
  8. ğŸ” Search Jobs by Keyword
  9. ğŸ¢ View Jobs by Company
  0. âŒ Exit
--------------------------------------------------------------------------------
ğŸ‘‰ Select an option (0-9):
```

### Command Line
```bash
# Scrape all 327 companies
$ ./scrape_batch.sh

# Scrape single company
$ ./scrape.sh "Databricks"

# View results
$ ./show_jobs.sh
```

## ğŸš€ Quick Start

### Prerequisites

- Docker Desktop installed
- 5GB disk space

### Setup (One-Time)

```bash
# 1. Clone the repo
git clone https://github.com/yourusername/InternTracker.git
cd InternTracker

# 2. Create environment file
cp .env.example .env

# 3. (Optional) Add your Gmail for notifications
nano .env  # Add SMTP settings

# 4. Build Docker images
docker-compose build
```

### Usage

#### ğŸ–¥ï¸ **Interactive CLI (Recommended)**
```bash
# Launch full-featured terminal app
./job_tracker.sh

# Features:
# - Run scrapes (full or single company)
# - View today's statistics & new jobs
# - Search jobs by keyword
# - Export master CSV log (auto-updated)
# - Track all-time metrics
```
ğŸ“– **[Full CLI Guide](CLI_GUIDE.md)**

#### âŒ¨ï¸ **Command Line**
```bash
# Scrape all companies (30-60 minutes)
./scrape_batch.sh

# Scrape one company (10-30 seconds)
./scrape.sh "Databricks"

# View results in terminal
./show_jobs.sh              # All jobs
./show_jobs.sh "NVIDIA"     # Jobs from specific company

# Master CSV log (auto-updated after scrapes)
open MASTER_JOB_LOG.csv     # All jobs in Excel/CSV format
```

**Clean up:**
```bash
docker-compose down         # Stop Docker
```

That's it! Docker automatically starts when scraping and stops when done.

## ğŸ¢ Tracked Companies (108)

**Quant/Trading Firms:**
Citadel, Two Sigma, Jane Street, HRT, D.E. Shaw, Jump Trading, Optiver, IMC, Akuna Capital, Susquehanna (SIG), Virtu Financial, DRW, Five Rings, Old Mission, Belvedere Trading, Tower Research

**FAANG+ Tech:**
Google, Meta, Amazon, Apple, Netflix, Microsoft, Adobe, Salesforce, Oracle, IBM

**AI/ML Companies:**
OpenAI, Anthropic, Scale AI, Hugging Face, Cohere

**Cloud/Infrastructure:**
Databricks, Snowflake, MongoDB, Confluent, HashiCorp

**Cybersecurity:**
CrowdStrike, Palo Alto Networks, Zscaler, Okta, SentinelOne, CrowdStrike

**Plus 60+ more** including fintech, autonomous vehicles, gaming, and enterprise software companies.

[Full list in `config/watchlist.yaml`](config/watchlist.yaml)

## ğŸ› ï¸ How It Works

1. **Scraper visits** each company's career page
2. **Extracts** job listings using Playwright (headless browser)
3. **Filters** for:
   - Internships only
   - US locations only
   - Summer 2026 positions
   - ML/AI, Cybersecurity, Data Engineering, Data Science roles
4. **Saves** to PostgreSQL database
5. **Sends email** if new jobs found
6. **Shuts down** Docker when complete

### Supported ATS Platforms

- âœ… Greenhouse (Stripe, Airbnb, Robinhood)
- âœ… Lever (Netflix, Lyft, Figma)
- âœ… Ashby (OpenAI, Anthropic, Scale AI)
- âœ… SmartRecruiters (LinkedIn, Bosch)
- âœ… Workday (Oracle, IBM)
- âœ… Generic HTML (with Playwright for all others)

## ğŸ“Š Job Categories

Jobs are automatically classified into:

- **ML/AI** - Machine Learning, Deep Learning, NLP, Computer Vision
- **Cybersecurity** - Security Engineering, Threat Detection, Incident Response  
- **Data Engineering** - ETL, Data Pipelines, Big Data, Spark
- **Data Science** - Analytics, Research Scientists, Data Analysts

## ğŸ“§ Email Notifications

Get notified when new jobs are found!

**Setup Gmail notifications:**

1. [Create Gmail App Password](https://support.google.com/accounts/answer/185833)
2. Edit `.env`:
```env
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password  # 16-character app password
SMTP_FROM=your-email@gmail.com
SMTP_TO=your-email@gmail.com
```

3. Run scraper - you'll get email with new jobs!

## â• Adding Companies

1. Open `config/watchlist.yaml`
2. Add company:
```yaml
  - company: "Your Company"
    url: "https://careers.company.com/jobs"
    source: generic  # or greenhouse, lever, ashby, etc.
```
3. Test:
```bash
./scrape.sh "Your Company"
```

## ğŸ–¥ï¸ Optional: Web Dashboard

View jobs in your browser:

```bash
# Start dashboard
docker-compose up -d api db

# Open browser
open http://localhost:8000

# Stop when done
docker-compose down
```

**Features:**
- ğŸ“Š Live statistics
- ğŸ” Search jobs
- ğŸ¢ Filter by company
- ğŸ“± Filter by category
- â° Countdown to next scrape

## ğŸ“ Project Structure

```
InternTracker/
â”œâ”€â”€ scrape.sh              # Main scraper command
â”œâ”€â”€ show_jobs.sh           # View results
â”œâ”€â”€ config/
â”‚   â””â”€â”€ watchlist.yaml     # 108 companies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest/            # Scrapers
â”‚   â”œâ”€â”€ core/              # Database models  
â”‚   â””â”€â”€ app/               # Optional web dashboard
â”œâ”€â”€ frontend/              # Dashboard UI
â””â”€â”€ docker-compose.yml     # Docker setup
```

## âš–ï¸ Legal & Ethics

- âœ… **Respectful scraping** - 1-3 requests/second per domain
- âœ… **Public data only** - Career pages accessible to everyone
- âœ… **Respects robots.txt** - Follows site guidelines
- âŒ **No LinkedIn** - Against their Terms of Service
- âœ… **Rate limiting** - Doesn't overload servers
- âœ… **User-Agent** - Identifies as bot

## ğŸ¤ Contributing

Contributions welcome!

- Add more companies
- Improve filtering logic
- Add new ATS platforms
- Fix bugs

## ğŸ“ License

MIT License - see [LICENSE](LICENSE)

## ğŸ‘¤ Author

**Yash Lad**
- GitHub: [@yashlad](https://github.com/yashlad)
- Email: yashlad727@gmail.com

## â­ Star History

If this helped your job search, please star the repo!

## ğŸ™ Acknowledgments

- Inspired by [Simplify Jobs](https://simplify.jobs/) internship tracker
- Built with FastAPI, PostgreSQL, Playwright
- Companies data from public career pages

---

**Happy job hunting! ğŸ¯**
